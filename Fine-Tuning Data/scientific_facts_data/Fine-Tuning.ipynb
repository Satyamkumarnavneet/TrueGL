{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_statements = pd.read_csv('all_statements.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = all_statements.sample(frac=0.85, random_state=42)\n",
    "val_set = all_statements.drop(train_set.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65962</th>\n",
       "      <td>American International Group has headquarters ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124723</th>\n",
       "      <td>Artemis brought and relieved disease in men.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162193</th>\n",
       "      <td>The pH scale measures the sweetness or bittern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91286</th>\n",
       "      <td>Leonardo Bonucci is a three-time member of the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55979</th>\n",
       "      <td>Ad-Rock's spouse is an American who was born i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87432</th>\n",
       "      <td>Wild Ones is by an American Singer.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86941</th>\n",
       "      <td>Purple has a genre.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64096</th>\n",
       "      <td>Human uses for gazelle include pets, research,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>Legion is the main character and title charact...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125762</th>\n",
       "      <td>Grace VanderWaal is from Suffern, New York.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143704 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                statement  labels\n",
       "65962   American International Group has headquarters ...       1\n",
       "124723       Artemis brought and relieved disease in men.       2\n",
       "162193  The pH scale measures the sweetness or bittern...       0\n",
       "91286   Leonardo Bonucci is a three-time member of the...       0\n",
       "55979   Ad-Rock's spouse is an American who was born i...       1\n",
       "...                                                   ...     ...\n",
       "87432                 Wild Ones is by an American Singer.       1\n",
       "86941                                 Purple has a genre.       1\n",
       "64096   Human uses for gazelle include pets, research,...       0\n",
       "3984    Legion is the main character and title charact...       1\n",
       "125762        Grace VanderWaal is from Suffern, New York.       1\n",
       "\n",
       "[143704 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The parrot has the atomic number of mammal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Natalie Wood worked with George Seaton.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ireland was a country Mother Teresa lived in.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Yellow Flicker Beat has been, at the American ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>James Garner did not star in television series.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169027</th>\n",
       "      <td>Dark Phoenix is an alias that Jean Grey is kno...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169036</th>\n",
       "      <td>Las Vegas is famous for its nightlife.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169044</th>\n",
       "      <td>In 2009, Scarlett Johansson released an album.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169053</th>\n",
       "      <td>Harlem is where Sean Combs was born.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169058</th>\n",
       "      <td>Bill Cosby has been the subject of sexual assa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25359 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                statement  labels\n",
       "5             The parrot has the atomic number of mammal.       0\n",
       "15                Natalie Wood worked with George Seaton.       1\n",
       "16          Ireland was a country Mother Teresa lived in.       1\n",
       "18      Yellow Flicker Beat has been, at the American ...       1\n",
       "26        James Garner did not star in television series.       0\n",
       "...                                                   ...     ...\n",
       "169027  Dark Phoenix is an alias that Jean Grey is kno...       1\n",
       "169036             Las Vegas is famous for its nightlife.       1\n",
       "169044     In 2009, Scarlett Johansson released an album.       1\n",
       "169053               Harlem is where Sean Combs was born.       1\n",
       "169058  Bill Cosby has been the subject of sexual assa...       0\n",
       "\n",
       "[25359 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_set[['statement', 'labels']])\n",
    "val_dataset = Dataset.from_pandas(val_set[['statement', 'labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model google/gemma-3-4b-it and tokenizer google/gemma-3-4b-it\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/gemma-3-4b-it\"\n",
    "tokenizer_name = None\n",
    "#tokenizer_name = 'bert-base-uncased' # in case the tokenizer of the original model does not work / is not applicable for some reason\n",
    "tokenizer_name = tokenizer_name if tokenizer_name else model_name\n",
    "print(f\"Using model {model_name} and tokenizer {tokenizer_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "  # Tokenize the 'statement' text. `padding=\"max_length\"` ensures all sequences have the same length.\n",
    "  # `truncation=True` cuts off text longer than the model's max input size.\n",
    "  return tokenizer(examples[\"statement\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Apply the tokenizer to the datasets\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Remove the original text column as the model doesn't need it after tokenization\n",
    "tokenized_train_dataset = tokenized_train_dataset.remove_columns([\"statement\"])\n",
    "tokenized_val_dataset = tokenized_val_dataset.remove_columns([\"statement\"])\n",
    "\n",
    "# Set the format to PyTorch tensors (or TensorFlow if you use TF)\n",
    "tokenized_train_dataset.set_format(\"torch\")\n",
    "tokenized_val_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=-1) # Get the index of the highest probability\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted') # Use 'weighted' for multiclass\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3,\n",
    "    # Quantization can still be useful for faster inference or lower VRAM on consumer GPUs\n",
    "    # load_in_4bit=True, # Uncomment if needed\n",
    "    device_map=\"auto\", # Good practice, handles device placement\n",
    "    # torch_dtype=torch.bfloat16, # Optional: Use if supported\n",
    "    # trust_remote_code=True, # Optional: Uncomment if required by the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'fine_tuned_weights' # where you will save the results too?\n",
    "\n",
    "num_train_epochs = 100 # let's keep it big for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Training Arguments ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=save_path,          # Directory to save the model and results\n",
    "    num_train_epochs=num_train_epochs,              # Total number of training epochs\n",
    "    per_device_train_batch_size=16,  # Batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # Batch size for evaluation\n",
    "    warmup_steps=500,                # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # Strength of weight decay\n",
    "    learning_rate=2e-5,              # Learning rate for the optimizer\n",
    "    logging_dir='./logs',            # Directory for storing logs\n",
    "    logging_steps=10,                # Log metrics every X steps\n",
    "    evaluation_strategy=\"epoch\",     # Evaluate model at the end of each epoch\n",
    "    save_strategy=\"epoch\",           # Save model checkpoint at the end of each epoch\n",
    "    load_best_model_at_end=True,     # Load the best model found during training at the end\n",
    "    metric_for_best_model=\"accuracy\",# Use accuracy to determine the best model\n",
    ")\n",
    "\n",
    "# Initialize the Trainer ---\n",
    "trainer = Trainer(\n",
    "    model=model,                         # The instantiated Transformers model to be trained\n",
    "    args=training_args,                  # Training arguments, defined above\n",
    "    train_dataset=tokenized_train_dataset, # Training dataset\n",
    "    eval_dataset=tokenized_val_dataset,  # Evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # Function to compute metrics during evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model ---\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the Model ---\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")\n",
    "\n",
    "# Save the Model ---\n",
    "trainer.save_model(save_path)\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
